{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "vwzoA7pc7Ru1",
        "outputId": "9e6887a5-bae1-47db-b6a0-4459e0afbf1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.0.1-cp38-cp38-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Installing collected packages: psutil, dgl\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed dgl-1.0.1 psutil-5.9.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJyd7FY6_cFa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjNRn5fB_ctw"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ4QvIIF7xbb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "from collections import namedtuple\n",
        "import dgl.function as fn\n",
        "from copy import deepcopy as dc\n",
        "import random\n",
        "import time\n",
        "from time import time\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9M6sGe_L-3"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLjmVoem_Lap"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "from collections import namedtuple\n",
        "import dgl.function as fn\n",
        "from copy import deepcopy as dc\n",
        "import random\n",
        "import time\n",
        "from time import time\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "class IM(object):\n",
        "    def __init__(self, max_budget, p, num_nodes, cost):\n",
        "        self.max_budget = max_budget\n",
        "        self.BUDGET = max_budget\n",
        "        assert(p <= 1 and p >= 0)\n",
        "        self.p = p\n",
        "        self.num_nodes = num_nodes\n",
        "        self.cost = cost\n",
        "\n",
        "    def compute_reward(self, state):\n",
        "        # reward is the number of additional nodes influenced\n",
        "        reward = 0\n",
        "        # each node has one chance to influence each neighbour\n",
        "        # print(state)\n",
        "        new_influenced = state.detach().cpu().numpy().ravel()\n",
        "        # print(new_influenced)\n",
        "        tot_influenced = state.detach().cpu().numpy().ravel()\n",
        "        while((new_influenced == 1).sum() >= 1):\n",
        "            # next = torch.full(\n",
        "            #     (self.num_nodes, 1),\n",
        "            #     0, \n",
        "            #     dtype = torch.long\n",
        "            #     )\n",
        "            next = np.zeros(self.num_nodes)\n",
        "            for e in range(self.g.number_of_edges()):\n",
        "                # print(new_influenced[self.g.edges()[0][e]])\n",
        "                if((new_influenced[self.g.edges()[0][e]] == 1) and \n",
        "                   not(tot_influenced[self.g.edges()[1][e]] == 1 or new_influenced[self.g.edges()[1][e]] == 1)):\n",
        "                    r = random.random()\n",
        "                    if(r < self.p):\n",
        "                        # node influenced\n",
        "                        next[self.g.edges()[1][e]] = 1\n",
        "                        reward += 1\n",
        "            # print(new_influenced)\n",
        "            tot_influenced = tot_influenced + new_influenced\n",
        "            new_influenced = next\n",
        "        return reward\n",
        "     \n",
        "    def step(self, action):\n",
        "        reward, sol, done = self._take_action(action)\n",
        "        \n",
        "        ob = self._build_ob()\n",
        "        self.sol = sol\n",
        "        info = {\"sol\": self.sol}\n",
        "\n",
        "        # need to convert ob to ndarray from tensor\n",
        "        ob = ob.detach().cpu().numpy().ravel()\n",
        "        next_state = np.copy(ob)\n",
        "        return next_state, reward, done, info\n",
        "    \n",
        "    def _take_action(self, action):\n",
        "        r1, r2 = 0, 0\n",
        "        num_iter = 100\n",
        "        for i in range(num_iter):\n",
        "            r1 += self.compute_reward(self.x[:-1])\n",
        "        if(self.x[action] == 0 and self.cost[action] <= self.max_budget):\n",
        "            self.x[action] = 1\n",
        "            self.x[-1] -= self.cost[action]\n",
        "            self.max_budget -= self.cost[action]\n",
        "        # write code for else case \n",
        "        next_sol = 0\n",
        "        for i in range(num_iter):\n",
        "            r2 += self.compute_reward(self.x[:-1])\n",
        "        done = self._check_done()\n",
        "        return (r2 - r1)/num_iter, next_sol, done\n",
        "\n",
        "    def _check_done(self): \n",
        "        inactive = (self.x[:-1] == 0).type(torch.float)\n",
        "        # print(inactive)\n",
        "        self.g.ndata['h'] = inactive\n",
        "        not_selected = dgl.sum_nodes(self.g, 'h')\n",
        "        self.g.ndata.pop('h')\n",
        "        done = (not_selected == 0) or (self.max_budget <= 0)\n",
        "        return done\n",
        "                \n",
        "    def _build_ob(self):\n",
        "        ob_x = self.x\n",
        "        # ob = torch.cat([ob_x], dim = 2)\n",
        "        # return ob\n",
        "        return ob_x\n",
        "    \n",
        "    # using num_samples = 1 as of now \n",
        "    def register(self, g, num_samples = 1):\n",
        "        self.g = g\n",
        "        self.g.set_n_initializer(dgl.init.zero_initializer)\n",
        "        t = torch.full((self.num_nodes, 1), 0, dtype=torch.float16)\n",
        "        # torch.full(\n",
        "            #     (self.num_nodes, 1),\n",
        "            #     0, \n",
        "            #     dtype = torch.long\n",
        "            #     )\n",
        "        self.x = torch.cat((t, torch.tensor([[self.max_budget]])), 0)\n",
        "        ob = self._build_ob()\n",
        "        return ob\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        state = np.zeros(self.num_nodes + 1)\n",
        "        state[-1] = self.BUDGET\n",
        "\n",
        "        t = torch.full((self.num_nodes, 1), 0, dtype=torch.float16)\n",
        "        self.max_budget = self.BUDGET\n",
        "        self.x = torch.cat((t, torch.tensor([[self.max_budget]])), 0)\n",
        "\n",
        "        return np.array(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncLgXZQ_j18"
      },
      "source": [
        "## Main "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVM_MOc97k_-",
        "outputId": "955548cb-2f12-4015-8c32-3bf61bc74524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0.],\n",
            "        [   0.],\n",
            "        [   0.],\n",
            "        [   0.],\n",
            "        [   0.],\n",
            "        [1000.]], dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "cost = torch.tensor([300, 300, 300, 300, 300])\n",
        "maxb = 1000\n",
        "env = IM(maxb, 0.6, 5, cost)\n",
        "src_ids = torch.tensor([0, 1, 2, 3])\n",
        "dst_ids = torch.tensor([1, 2, 3, 4])\n",
        "g = dgl.graph((src_ids, dst_ids), num_nodes=5)\n",
        "ob = env.register(g)\n",
        "\n",
        "\n",
        "print(ob)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPT25dxEicKS"
      },
      "source": [
        "### greedy\n",
        "\n",
        "At each step pick the node with highest influence per cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kCeEEX9ibyW",
        "outputId": "1d15f7fe-6725-4619-b319-4a12e265eb35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " reward_per_cost :  [0.0037     0.00463333 0.00333333 0.00206667 0.        ]\n",
            "choice :  1\n",
            "tensor([[  0.],\n",
            "        [  1.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [  0.],\n",
            "        [700.]], dtype=torch.float16) tensor(700)\n",
            " reward_per_cost :  [ 0.00036667  0.         -0.0008      0.00216667 -0.00056667]\n",
            "choice :  3\n",
            "tensor([[  0.],\n",
            "        [  1.],\n",
            "        [  0.],\n",
            "        [  1.],\n",
            "        [  0.],\n",
            "        [400.]], dtype=torch.float16) tensor(400)\n",
            "1.56\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "cost = torch.tensor([300, 300, 300, 300, 300])\n",
        "maxb = 1000\n",
        "env = IM(maxb, 0.6, 5, cost)\n",
        "src_ids = torch.tensor([0, 1, 2, 3])\n",
        "dst_ids = torch.tensor([1, 2, 3, 4])\n",
        "g = dgl.graph((src_ids, dst_ids), num_nodes=5)\n",
        "ob = env.register(g)\n",
        "\n",
        "def greedy():\n",
        "    score = 0\n",
        "    n = env.num_nodes\n",
        "    while True:\n",
        "        reward_per_cost = np.zeros(n)\n",
        "\n",
        "        done = False\n",
        "        for i in range(n):\n",
        "            temp = copy.deepcopy(env)\n",
        "            if env.x[i] == 0 and env.cost[i] <= env.max_budget :\n",
        "                _, reward, _, _ = temp.step(i)\n",
        "                reward_per_cost[i] = reward / temp.cost[i]\n",
        "            \n",
        "        choice = np.argmax(reward_per_cost)\n",
        "        if reward_per_cost[choice] == 0:\n",
        "            break\n",
        "\n",
        "        print(\" reward_per_cost : \", reward_per_cost)\n",
        "        print(\"choice : \", choice)\n",
        "        \n",
        "        _, reward, done, _ = env.step(choice)\n",
        "        print(env.x, env.max_budget)\n",
        "        score += reward\n",
        "\n",
        "        if done == True:\n",
        "            break\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "score = greedy()\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d9GbLCYmftW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
